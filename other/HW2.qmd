---
title: "Homework 2"
author: "Sonya Eason"
format: pdf
editor: visual
---

## Exercise 1

The variance of a binary, or Bernoulli, random variable is the smallest when p = 0  or p = 1 and largest when p = 0.5.

$$
Var(X) = p(1-p)
$$
If we view the variance as a function that exists on [0,1], which we know to be the support of the parameter p, it's easy to see where the variance is maximized and minimized. 

```{r}
p <- seq(0, 1, by = 0.001)
var <- p*(1-p)
plot(p, var, type = "l")

#referenced chat gpt to determine how to fix my specification of the plot 
#function here, asked this prompt "how to plot a line in R"
```

## Exercise 2

Hypergeometric and binomial random variables are similar in that they are counting number of successes. The difference is that in a hypergeometric distribution the probability of success is dynamic, while in binomial, we believe this probability of success to remain constant. Another similarity is in the fact that we have a defined n selections out of which we can have a maximum of n successes. The reason for the dynamic nature of hypergeometric is because in each potential selection we do so without replacement. 


## Exercise 3

A poisson random variable counts independent events that happen at a constant average rate. The exponential distribution can represent the time between events in such a Poisson process.

## Exercise 4 

While geometric looks at the number of failures before the first success, an exponential random variable will represent the time between events or before an event. From this it becomes clear that an exponential random variable is continuous and a geometric random variable is discrete. 


## Exercise 5

A hypergeometric distribution could be useful in modeling the probability of electing X board members from the math department. This is because when a member is elected, they are NOT replaced and so the probability of electing another member from the same department is clearly dynamic. We're looking at counts of "success" without replacement, so hypergeometric seems to be the best distribution to use. 


## Exercise 6

Poisson may be useful because we are looking at the number of events that happen, specifically the number of particles, but also these events are defined by the fact that they occur independently at a constant average rate. For example, there may be a certain number of particles on average in each cubic foot, so the event of particles in a section of cubic foot on one side of Minnesota and the count of particles in another section would be independent events in theory that have the same average rate. 


## Exercise 7

A Bernoulli distribution might be useful to model if a newborn has a low birthweight because we are considering independent events of a single (n=1) newborn's birthweight, so the only plausible outcomes of each event would be 0 or 1 which is supported by a Bernoulli distribution.


## Exercise 8


A poisson distribution would be useful in modeling number of matings. Mating is an event that can occur or not occur, and these events likely occur at a constant rate. Since each event consists of number of matings, we need to quantify this by a distribution that has support over [0, 1, 2, 3, ...], so Poisson is suitable. We expect there to be an average number of successful matings for older elephants and an average number of successful matings for younger elephants which we could utilize to evaluate our quesiton. The only other potential distribution is binomial which would not work since we do not have information about number of trials or number of attempted matings. 


## Exercise 9

Using a gamma distribution, we could look at the amount of time between 10th drop of rain and the 30th drop of rain, assuming that rain drops fall at a constant average rate and are independent of one another. 

## Exercise 10

```{r}
observed <- rbinom(1000, 10, 0.8)
hist(observed)
```


```{r}
p <- rbeta(1000, 4, 1)
y <- rbinom(1000, 10, p)
hist(y)
```
Although they both are assymetric, the original binomial appears to be more symmetric, and  the beta-binomial distribution has a strong left skew. This leads me to believe the standard deviation is not a reliable metric of variability for beta-binomial. In the beta-binomial plot, lower values like 1 and 2 appeared to show up, which were not seen in the plain binomial distribution. The possible values, however, should be the same: 0 to 10. While the means of both the plain binomial and the beta-binomail are very similar, it seems like the standard deviation is larger for the beta-binomial distribution.

```{r}
mean(observed)
mean(y)

sd(observed)
sd(y)
```

